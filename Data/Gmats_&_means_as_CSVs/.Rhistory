END.est.5 <- FoldedNormal( cbind( END.Bayes5.1$Sol[,1],
( END.Bayes5.1$Sol[,1] + END.Bayes5.1$Sol[,2] ),
( END.Bayes5.1$Sol[,1] + END.Bayes5.1$Sol[,3] ),
( END.Bayes5.1$Sol[,1] + END.Bayes5.1$Sol[,4] ),
( END.Bayes5.1$Sol[,1] + END.Bayes5.1$Sol[,2] + END.Bayes5.1$Sol[,4] + END.Bayes5.1$Sol[,6] ),
( END.Bayes5.1$Sol[,1] + END.Bayes5.1$Sol[,3] + END.Bayes5.1$Sol[,4] + END.Bayes5.1$Sol[,7] ) ) )
END.est.6 <- FoldedNormal( cbind( END.Bayes6.1$Sol[,1],
( END.Bayes6.1$Sol[,1] + END.Bayes6.1$Sol[,2] ),
( END.Bayes6.1$Sol[,1] + END.Bayes6.1$Sol[,3] ),
( END.Bayes6.1$Sol[,1] + END.Bayes6.1$Sol[,4] ),
( END.Bayes6.1$Sol[,1] + END.Bayes6.1$Sol[,2] + END.Bayes6.1$Sol[,4] + END.Bayes6.1$Sol[,6] ),
( END.Bayes6.1$Sol[,1] + END.Bayes6.1$Sol[,3] + END.Bayes6.1$Sol[,4] + END.Bayes6.1$Sol[,7] ) ) )
par( mfrow=c(1, 3) )
plot( apply( END.estimates, 2, mean ), type="n", xaxt="n", ylab=expression(italic("n"["D"])), xlab="Trait type", xlim=c(0.7,3.3), ylim=c(0,2), main="END with k as covariate")
axis(side=1, c("LH","M","S"), at=c(1,2,3))
lines( c(1,1), c(hpd(END.estimates[,1])), lwd=2 )
lines( c(2,2), c(hpd(END.estimates[,2])), lwd=2 )
lines( c(3,3), c(hpd(END.estimates[,3])), lwd=2 )
lines( c(1.1,1.1), c(hpd(END.estimates[,4])), lwd=2 )
lines( c(2.1,2.1), c(hpd(END.estimates[,5])), lwd=2 )
lines( c(3.1,3.1), c(hpd(END.estimates[,6])), lwd=2 )
points( 1:3, ENDfixed[1:3], pch=16, cex=2)
#animals - filled points ^ #plants - open points v
points( 1.1:3.1, ENDfixed[4:6], pch=21, bg="white", cex=2)
plot( apply( END.est.5, 2, mean ), type="n", xaxt="n", ylab=expression(italic("scaled n"["D"])), xlab="Trait type", xlim=c(0.7,3.3), ylim=c(0,0.7), main="END / k")
axis(side=1, c("LH","M","S"), at=c(1,2,3))
lines( c(1,1), c(hpd(END.est.5[,1])), lwd=2 )
lines( c(2,2), c(hpd(END.est.5[,2])), lwd=2 )
lines( c(3,3), c(hpd(END.est.5[,3])), lwd=2 )
lines( c(1.1,1.1), c(hpd(END.est.5[,4])), lwd=2 )
lines( c(2.1,2.1), c(hpd(END.est.5[,5])), lwd=2 )
lines( c(3.1,3.1), c(hpd(END.est.5[,6])), lwd=2 )
points( 1:3, apply(END.est.5[,1:3], 2, mean), pch=16, cex=2)
#animals - filled points ^ #plants - open points v
points( 1.1:3.1, apply(END.est.5[,4:6], 2, mean), pch=21, bg="white", cex=2)
plot( apply( END.est.6, 2, mean ), type="n", xaxt="n", ylab=expression(italic("scaled n"["D"])), xlab="Trait type", xlim=c(0.7,3.3), ylim=c(0,0.4), main="END / k^2")
axis(side=1, c("LH","M","S"), at=c(1,2,3))
lines( c(1,1), c(hpd(END.est.6[,1])), lwd=2 )
lines( c(2,2), c(hpd(END.est.6[,2])), lwd=2 )
lines( c(3,3), c(hpd(END.est.6[,3])), lwd=2 )
lines( c(1.1,1.1), c(hpd(END.est.6[,4])), lwd=2 )
lines( c(2.1,2.1), c(hpd(END.est.6[,5])), lwd=2 )
lines( c(3.1,3.1), c(hpd(END.est.6[,6])), lwd=2 )
points( 1:3, apply(END.est.6[,1:3], 2, mean), pch=16, cex=2)
#animals - filled points ^ #plants - open points v
points( 1.1:3.1, apply(END.est.6[,4:6], 2, mean), pch=21, bg="white", cex=2)
par( mfrow=c(1,1))
```
The next code block performs the model selection for 'maximum evolvability'. In this the best fitting model as judged by BIC was model1, but the DIC (Bayesian) approach supported model3. We opted to select model3; the ∆BIC between the models was <5 and the ∆DIC was mauch larger at ~20. Model3 was: `Emax ~ trait.type + taxon2 + trait.no + random(study.code) + random(species)`.
```{r model_selection_for_Emax, echo=FALSE, results='hide', message=FALSE, fig.keep='none'}
# now to analyse Max. Evolvability
EMAX.reml1 <- lmer(Emax ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
EMAX.reml2 <- lmer(Emax ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
EMAX.reml3 <- lmer(Emax ~ 1 + trait.type + taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
EMAX.reml4 <- lmer(Emax ~ 1 + trait.type * taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
BICtab( EMAX.reml1, EMAX.reml2, EMAX.reml3, EMAX.reml4, weights=T, nobs=nrow(gmats) )
# this suggests that we don't need the interaction!?
# dBIC df weight
# EMAX.reml1  0.0 7  0.6194
# EMAX.reml2  1.6 9  0.2806
# EMAX.reml3  4.4 8  0.0688
# EMAX.reml4  6.0 10 0.0312
# now I'll use the parametric bootstrap to confirm...
# model 1 vs model 2
LikRatioSim <- function( mod ) {
y.sim <- simulate(mod, nsim = 1)  # one set of simulated data
model.lower <- lmer(y.sim$sim_1 ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
model.full  <- lmer(y.sim$sim_1 ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
LRSim <-  -as.numeric(deviance(model.full) - deviance(model.lower))
return(LRSim)
rm(y.sim, model.lower, model.full, LRSim)
}
LikRatParBoot <- replicate(n = 1000, LikRatioSim( EMAX.reml1 ))
LR.model <- -as.numeric(deviance( EMAX.reml2 ) - deviance( EMAX.reml1 ))
mean(c((LikRatParBoot > LR.model), 1))
# 0.705 supports sticking with model 1 over model 2
# model 1 vs model 3
LikRatioSim <- function( mod ) {
y.sim <- simulate(mod, nsim = 1)  # one set of simulated data
model.lower <- lmer(y.sim$sim_1 ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
model.full  <- lmer(y.sim$sim_1 ~ 1 + trait.type + taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
LRSim <-  -as.numeric(deviance(model.full) - deviance(model.lower))
return(LRSim)
rm(y.sim, model.lower, model.full, LRSim)
}
LikRatParBoot <- replicate(n = 1000, LikRatioSim( EMAX.reml1 ))
LR.model <- -as.numeric(deviance( EMAX.reml3 ) - deviance( EMAX.reml1 ))
mean(c((LikRatParBoot > LR.model), 1))
# 0.423 supports sticking with model 1 over model 3
EMAX.Bayes0 <- MCMCglmm(Emax ~ 1, nitt=100000, burnin=10000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
summary( EMAX.Bayes0 )$solutions
# post.mean  l-95% CI u-95% CI eff.samp        pMCMC
# (Intercept) 0.6067565 0.2490954 0.962691     3000 0.0003333333
EMAXB0 <- rfnorm(3000, mean(EMAX.Bayes0$Sol[,1]), sd(EMAX.Bayes0$Sol[,1]))
mean( EMAXB0 )	;	hpd( EMAXB0 ) 	 ;	  Mode( EMAXB0 )
# 0.6112283		0.2587635 -- 0.9674873		0.4653126
EMAX.Bayes1 <- MCMCglmm(Emax ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
EMAX.Bayes2 <- MCMCglmm(Emax ~ 1 + trait.type * taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
EMAX.Bayes3 <- MCMCglmm(Emax ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
EMAX.Bayes4 <- MCMCglmm(Emax ~ 1 + trait.type * taxon2 + trait.no, nitt=500000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
# DIC is in disagreement with BIC and LRsim... I going to err on the side of caution and go with model3
EMAX.Bayes1$DIC ; EMAX.Bayes2$DIC ; EMAX.Bayes3$DIC	; EMAX.Bayes4$DIC
# 287.4724			287.9171			268.0664		268.3305
plot(EMAX.Bayes3$VCV)
acf(EMAX.Bayes3$VCV)
plot(EMAX.Bayes3$Sol)
acf(EMAX.Bayes3$Sol)
summary(EMAX.Bayes3)$solutions
# post.mean   l-95% CI  u-95% CI eff.samp     pMCMC
# (Intercept)  0.09065319 -0.9488144 1.0829023 3167.000 0.8601200
# trait.typeM  1.13577784 -0.5354211 3.0375432 3167.000 0.1957689
# trait.typeS  0.57123654 -0.6798971 1.7049119 3167.000 0.3328071
# taxon2P     -0.64535373 -1.6896664 0.3090051 2981.949 0.1951374
# trait.no     0.06964617 -0.1448010 0.2947385 3167.000 0.5424692
```
Here are the results of our selected model; filled points for estimates for animals, open points for plants, lines are the extent of the 95% credible intervals from the posterior distribution.
```{r Emax_results, results='hide', fig.height=4, fig.width=4, echo=FALSE}
EMAX.estimates <- cbind( EMAX.Bayes3$Sol[,1],
( EMAX.Bayes3$Sol[,1] + EMAX.Bayes3$Sol[,2] ),
( EMAX.Bayes3$Sol[,1] + EMAX.Bayes3$Sol[,3] ),
( EMAX.Bayes3$Sol[,1] + EMAX.Bayes3$Sol[,4] ),
( EMAX.Bayes3$Sol[,1] + EMAX.Bayes3$Sol[,2] + EMAX.Bayes3$Sol[,4] ),
( EMAX.Bayes3$Sol[,1] + EMAX.Bayes3$Sol[,3] + EMAX.Bayes3$Sol[,4] ) )
colnames(EMAX.estimates) <- c('A.LH','A.M','A.S','P.LH','P.M','P.S')
EMAX.estimates <- FoldedNormal( EMAX.estimates )
apply( EMAX.estimates, 2, mean )
apply( EMAX.estimates, 2, Mode )
apply( EMAX.estimates, 2, hpd )
# A.LH       A.M       A.S      P.LH       P.M        P.S
# mean 0.4334804 1.2491385 0.7823528 0.5888987 0.9102743 0.5250986
# mode 0.2579401 0.0065128 0.8597651 0.8885794 0.5685091 0.1098872
# -95% 0.0003335 0.0007561 0.0011306 0.0001440 0.0028559 0.0002239
# +95% 1.0429934 2.8338943 1.8755535 1.3894593 2.2157249 1.2813908
# EMAX plot
EMAXfixed <- apply( EMAX.estimates, 2, mean )
plot(EMAXfixed, type="n", xaxt="n", ylab="EMAX values", xlab="Trait type", xlim=c(0.7,3.3), ylim=c(0, 5), main="Max. Evolvability")
axis(side=1, c("LH","M","S"), at=c(1,2,3))
lines( c(1,1), c(hpd(EMAX.estimates[,1])), lwd=2 )
lines( c(2,2), c(hpd(EMAX.estimates[,2])), lwd=2 )
lines( c(3,3), c(hpd(EMAX.estimates[,3])), lwd=2 )
lines( c(1.1,1.1), c(hpd(EMAX.estimates[,4])), lwd=2 )
lines( c(2.1,2.1), c(hpd(EMAX.estimates[,5])), lwd=2 )
lines( c(3.1,3.1), c(hpd(EMAX.estimates[,6])), lwd=2 )
points( 1:3, EMAXfixed[1:3], pch=16, cex=2)
#animals - filled points ^ #plants - open points v
points( 1.1:3.1, EMAXfixed[4:6], pch=21, bg="white", cex=2)
```
The next code block performs the model selection for 'total genetic variance'. In this case the best fitting model as judged by BIC was model2, with the bootstrap supporting model1 and the DIC (Bayesian) approach supporting model3. We opted to select model3. It is worth noting that the estimates from models 2 & 3 were correlated at *r*>0.94. Model3 was: `TGV ~ trait.type + taxon2 + trait.no + random(study.code) + random(species)`.
```{r model_selection_for_TGV, echo=FALSE, results='hide', message=FALSE, fig.keep='none'}
# TGV analysis
TGV.reml1 <- lmer(TGV ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
TGV.reml2 <- lmer(TGV ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
TGV.reml3 <- lmer(TGV ~ 1 + trait.type + taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
TGV.reml4 <- lmer(TGV ~ 1 + trait.type * taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
# model2 is the best-fitting with REML and BIC
BICtab( TGV.reml1, TGV.reml2, TGV.reml3, TGV.reml4, weights=T, nobs=nrow(gmats) )
# dBIC df weight
# TGV.reml2  0.0 9  0.89568
# TGV.reml4  4.4 10 0.09952
# TGV.reml1 10.7 7  0.00432
# TGV.reml3 15.1 8  < 0.001
# now the parametric bootstrap
# model 1 vs model 2
LikRatioSim <- function( mod ) {
y.sim <- simulate(mod, nsim = 1)  # one set of simulated data
model.lower <- lmer(y.sim$sim_1 ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
model.full  <- lmer(y.sim$sim_1 ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
LRSim <-  -as.numeric(deviance(model.full) - deviance(model.lower))
return(LRSim)
rm(y.sim, model.lower, model.full, LRSim)
}
LikRatParBoot <- replicate(n = 1000, LikRatioSim( TGV.reml1 ))
LR.model <- -as.numeric(deviance( TGV.reml2 ) - deviance( TGV.reml1 ))
mean(c((LikRatParBoot > LR.model), 1))
# 0.776 bootstrap doesn't support model2 over model1 in contrast with BIC...
# model 2 vs model 4
LikRatioSim <- function( mod ) {
y.sim <- simulate(mod, nsim = 1)  # one set of simulated data
model.lower <- lmer(y.sim$sim_1 ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
model.full  <- lmer(y.sim$sim_1 ~ 1 + trait.type * taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
LRSim <-  -as.numeric(deviance(model.full) - deviance(model.lower))
return(LRSim)
rm(y.sim, model.lower, model.full, LRSim)
}
LikRatParBoot <- replicate(n = 1000, LikRatioSim( TGV.reml2 ))
LR.model <- -as.numeric(deviance( TGV.reml4 ) - deviance( TGV.reml2 ))
mean(c((LikRatParBoot > LR.model), 1))
# 0.642 stay with model 2
TGV.Bayes0 <- MCMCglmm(TGV ~ 1, nitt=500000, burnin=1000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
summary( TGV.Bayes0 )$solutions
TGVB0 <- rfnorm( length( TGV.Bayes0$Sol[,1] ), mean( TGV.Bayes0$Sol[,1] ), sd( TGV.Bayes0$Sol[,1] ) )
mean( TGVB0 )	;	hpd( TGVB0 ) 		 ;	 Mode( TGVB0 )
# 3.135937		0.001847855 -to- 7.566797628		2.940357
TGV.Bayes1 <- MCMCglmm(TGV ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
TGV.Bayes2 <- MCMCglmm(TGV ~ 1 + trait.type * taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
TGV.Bayes3 <- MCMCglmm(TGV ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
TGV.Bayes4 <- MCMCglmm(TGV ~ 1 + trait.type * taxon2 + trait.no, nitt=500000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
# DIC suggests that model3 is a better fit than model2
TGV.Bayes1$DIC ; TGV.Bayes2$DIC ; TGV.Bayes3$DIC	;	TGV.Bayes4$DIC
# 776.5418			777.4574			740.8967			741.07
# the shared coef.s are highly correlated (0.95), so I'm going to err on the side of complexity and go with model3
cor( c(colMeans( TGV.Bayes2$Sol )[1:5]), c(colMeans( TGV.Bayes3$Sol )) )
plot(TGV.Bayes3$VCV)
acf(TGV.Bayes3$VCV)
plot(TGV.Bayes3$Sol)
acf(TGV.Bayes3$Sol)
summary(TGV.Bayes3)$solutions
# post.mean   l-95% CI  u-95% CI eff.samp     pMCMC
# (Intercept) -0.4570179 -19.554800 20.442918 2791.130 0.9573729
# trait.typeM 20.2472241 -17.633004 63.580113 2981.970 0.3151247
# trait.typeS  2.7124723 -18.610255 27.785068 3598.117 0.8317019
# taxon2P     -2.9255618 -22.614285 16.022980 3004.807 0.7786549
# trait.no     0.2375523  -4.358424  4.294138 3167.000 0.9131670
TGV.estimates <- cbind( TGV.Bayes3$Sol[,1],
( TGV.Bayes3$Sol[,1] + TGV.Bayes3$Sol[,2] ),
( TGV.Bayes3$Sol[,1] + TGV.Bayes3$Sol[,3] ),
( TGV.Bayes3$Sol[,1] + TGV.Bayes3$Sol[,4] ),
( TGV.Bayes3$Sol[,1] +TGV.Bayes3$Sol[,2] +TGV.Bayes3$Sol[,4] ),
( TGV.Bayes3$Sol[,1] +TGV.Bayes3$Sol[,3] +TGV.Bayes3$Sol[,4] ) )
colnames(TGV.estimates) <- c('A.LH','A.M','A.S','P.LH','P.M','P.S')
TGV.estimates <- FoldedNormal( TGV.estimates )
# Tabulate estimates
apply( TGV.estimates, 2, mean )
apply( TGV.estimates, 2, Mode )
apply( TGV.estimates, 2, hpd )
# A.LH       A.M       A.S      P.LH       P.M       P.S
# mean 8.622775 25.408110 14.317302  9.383316 24.088053 11.043411
# mode 17.15973 23.57304 21.19176   17.36984  39.67697  10.85037
# -95%  0.006315  0.2961  0.003593  0.008477  0.008882  0.0068360
# +95% 18.113191 52.4658 30.889906 19.636975 50.480431 22.8630851
```
Here are the results of our selected model for *tgv*; filled points for estimates for animals, open points for plants, lines are the extent of the 95% credible intervals from the posterior distribution.
```{r TGV_results, results='hide', fig.height=4, fig.width=4, echo=FALSE}
TGVfixed <- apply( TGV.estimates, 2, mean )
plot(TGVfixed, type="n", xaxt="n", ylab="TGV values", xlab="Trait type", xlim=c(0.7,3.3), ylim=c(0,75), main="Total Genetic Variance")
axis(side=1, c("LH","M","S"), at=c(1,2,3))
lines( c(1,1), c(hpd(TGV.estimates[,1])), lwd=2 )
lines( c(2,2), c(hpd(TGV.estimates[,2])), lwd=2 )
lines( c(3,3), c(hpd(TGV.estimates[,3])), lwd=2 )
lines( c(1.1,1.1), c(hpd(TGV.estimates[,4])), lwd=2 )
lines( c(2.1,2.1), c(hpd(TGV.estimates[,5])), lwd=2 )
lines( c(3.1,3.1), c(hpd(TGV.estimates[,6])), lwd=2 )
points( 1:3, TGVfixed[1:3], pch=16, cex=2)
#animals - filled points ^ #plants - open points v
points( 1.1:3.1, TGVfixed[4:6], pch=21, bg="white", cex=2)
```
The next code block performs the model selection for *gmax*, the principal eigenvalue of **G**. In this case the best fitting model as judged by BIC and the bootstrap was model2, with the DIC (Bayesian) approach supporting model3. We opted to select model3. It is worth noting that the estimates from models 2 & 3 were correlated at *r*>0.94. Model3 was: `gmax ~ trait.type + taxon2 + trait.no + random(study.code) + random(species)`.
```{r model_selection_Gmax, echo=FALSE, results='hide', message=FALSE, fig.keep='none'}
gmax.reml1 <- lmer(gmax ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
gmax.reml2 <- lmer(gmax ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
gmax.reml3 <- lmer(gmax ~ 1 + trait.type + taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
gmax.reml4 <- lmer(gmax ~ 1 + trait.type * taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
# BIC reccommends model2
BICtab( gmax.reml1, gmax.reml2, gmax.reml3, gmax.reml4, weights=T, nobs=nrow(gmats) )
# dBIC df weight
# gmats.reml2  0.0 9  0.89211
# gmats.reml4  4.4 10 0.09912
# gmats.reml1  9.5 7  0.00789
# gmats.reml3 13.8 8  < 0.001
# model 2 vs model 4
LikRatioSim <- function( mod ) {
y.sim <- simulate(mod, nsim = 1)  # one set of simulated data
model.lower <- lmer(y.sim$sim_1 ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
model.full  <- lmer(y.sim$sim_1 ~ 1 + trait.type * taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
LRSim <-  -as.numeric(deviance(model.full) - deviance(model.lower))
return(LRSim)
rm(y.sim, model.lower, model.full, LRSim)
}
LikRatParBoot <- replicate(n = 1000, LikRatioSim( gmax.reml2 ))
LR.model <- -as.numeric(deviance( gmax.reml4 ) - deviance( gmax.reml2 ))
mean(c((LikRatParBoot > LR.model), 1))
# 0.735 stay with model 2
gmax.Bayes1 <- MCMCglmm(gmax ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
gmax.Bayes2 <- MCMCglmm(gmax ~ 1 + trait.type * taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
gmax.Bayes3 <- MCMCglmm(gmax ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
gmax.Bayes4 <- MCMCglmm(gmax ~ 1 + trait.type * taxon2 + trait.no, nitt=500000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
# Bayesian approach supports model 3
gmax.Bayes1$DIC ; gmax.Bayes2$DIC ; gmax.Bayes3$DIC  ;	gmax.Bayes4$DIC
# 801.9224			804.683				774.3294			777.2449
# using model3 gives estimates that are correlated at >0.94 with model2, so I'm going with model3
cor( c(colMeans( gmax.Bayes2$Sol )[1:5]), c(colMeans( gmax.Bayes3$Sol )) )
plot(gmax.Bayes3$VCV)
acf(gmax.Bayes3$VCV)
plot(gmax.Bayes3$Sol)
acf(gmax.Bayes3$Sol)
summary(gmax.Bayes3)$solutions
#              post.mean   l-95% CI  u-95% CI eff.samp     pMCMC
# (Intercept) -2.1772503 -24.356400 19.024930 3167.000 0.8487528
# trait.typeM 12.2396237 -15.523725 40.112034 3562.468 0.3808020
# trait.typeS  0.9493931 -23.160816 24.021480 3262.508 0.9340069
# taxon2P     -1.7168857 -20.590525 18.684758 2818.922 0.8658036
# trait.no     0.6474424  -3.782605  5.165388 2925.330 0.7843385
gmax.estimates <- cbind( gmax.Bayes3$Sol[,1],
( gmax.Bayes3$Sol[,1] + gmax.Bayes3$Sol[,2] ),
( gmax.Bayes3$Sol[,1] + gmax.Bayes3$Sol[,3] ),
( gmax.Bayes3$Sol[,1] + gmax.Bayes3$Sol[,4] ),
( gmax.Bayes3$Sol[,1] +gmax.Bayes3$Sol[,2] +gmax.Bayes3$Sol[,4] ),
( gmax.Bayes3$Sol[,1] +gmax.Bayes3$Sol[,3] +gmax.Bayes3$Sol[,4] ) )
gmax.estimates <- FoldedNormal( gmax.estimates )
colnames(gmax.estimates) <- c('A.LH','A.M','A.S','P.LH','P.M','P.S')
# Tabulate estimates
apply( gmax.estimates, 2, mean )
apply( gmax.estimates, 2, Mode )
apply( gmax.estimates, 2, hpd )
# A.LH       A.M       A.S      P.LH       P.M       P.S
# 9.071529 17.573916 14.774674 22.417751 29.892646 11.165447
# 23.761995 11.810164 19.365173  6.093903 57.117965  4.838458
# 3.2708e-04  0.003470 2.0487e-04 4.5605e-04  0.00434 4.8361e-04
# 2.2386e+01 42.566804 3.6349e+01 5.4547e+01 73.60713 2.7470e+01
```
Here are the results of our selected model for *gmax*; filled points for estimates for animals, open points for plants, lines are the extent of the 95% credible intervals from the posterior distribution.
```{r gmax_results, results='hide', fig.height=4, fig.width=4, echo=FALSE}
gmaxfixed <- apply( gmax.estimates, 2, mean )
plot(gmaxfixed, type="n", xaxt="n", ylab="gmax values", xlab="Trait type", xlim=c(0.7,3.3), ylim=c(0,50), main="Gmax (1st eigenvalue)")
axis(side=1, c("LH","M","S"), at=c(1,2,3))
lines( c(1,1), c(hpd(gmax.estimates[,1])), lwd=2 )
lines( c(2,2), c(hpd(gmax.estimates[,2])), lwd=2 )
lines( c(3,3), c(hpd(gmax.estimates[,3])), lwd=2 )
lines( c(1.1,1.1), c(hpd(gmax.estimates[,4])), lwd=2 )
lines( c(2.1,2.1), c(hpd(gmax.estimates[,5])), lwd=2 )
lines( c(3.1,3.1), c(hpd(gmax.estimates[,6])), lwd=2 )
points( 1:3, gmaxfixed[1:3], pch=16, cex=2)
#animals - filled points ^ #plants - open points v
points( 1.1:3.1, gmaxfixed[4:6], pch=21, bg="white", cex=2)
```
The next code block performs the model selection for 'average evolvability'. In this case the best fitting model as judged by BIC and the bootstrap was model2, with the DIC (Bayesian) approach supporting model3. We opted to select model3. It is worth noting that the estimates from models 2 & 3 were correlated at *r*>0.93. Model3 was: `AEvo ~ trait.type + taxon2 + trait.no + random(study.code) + random(species)`.
```{r average_evolvability_model_selection, echo=FALSE, results='hide', message=FALSE}
AEvo.reml1 <- lmer(AEvo ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
AEvo.reml2 <- lmer(AEvo ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
AEvo.reml3 <- lmer(AEvo ~ 1 + trait.type + taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
AEvo.reml4 <- lmer(AEvo ~ 1 + trait.type * taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
# BIC comes out in favour of model2 again...
BICtab( AEvo.reml1, AEvo.reml2, AEvo.reml3, AEvo.reml4, weights=T, nobs=81 )
# dBIC df weight
# AEvo.reml2  0.0 9  0.7300
# AEvo.reml1  2.9 7  0.1700
# AEvo.reml4  4.4 10 0.0811
# AEvo.reml3  7.3 8  0.0189
# model 1 vs model 2
LikRatioSim <- function( mod ) {
y.sim <- simulate(mod, nsim = 1)  # one set of simulated data
model.lower <- lmer(y.sim$sim_1 ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
model.full  <- lmer(y.sim$sim_1 ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
LRSim <-  -as.numeric(deviance(model.full) - deviance(model.lower))
return(LRSim)
rm(y.sim, model.lower, model.full, LRSim)
}
LikRatParBoot <- replicate(n = 1000, LikRatioSim( AEvo.reml1 ))
LR.model <- -as.numeric(deviance( AEvo.reml2 ) - deviance( AEvo.reml1 ))
mean(c((LikRatParBoot > LR.model), 1))
# 0.769 nothing in it between model 2 & model 1  <-  this is not in agreement with BIC...
# model 2 vs model 4
LikRatioSim <- function( mod ) {
y.sim <- simulate(mod, nsim = 1)  # one set of simulated data
model.lower <- lmer(y.sim$sim_1 ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
model.full  <- lmer(y.sim$sim_1 ~ 1 + trait.type * taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
LRSim <-  -as.numeric(deviance(model.full) - deviance(model.lower))
return(LRSim)
rm(y.sim, model.lower, model.full, LRSim)
}
LikRatParBoot <- replicate(n = 1000, LikRatioSim( AEvo.reml2 ))
LR.model <- -as.numeric(deviance( AEvo.reml4 ) - deviance( AEvo.reml2 ))
mean(c((LikRatParBoot > LR.model), 1))
# 0.505 nothing in it between model 2 and 4 either...
# Bayesian version
AEvo.Bayes0 <- MCMCglmm(AEvo ~ 1, nitt=500000, burnin=1000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
summary( AEvo.Bayes0 )$solutions
# post.mean   l-95% CI u-95% CI eff.samp    pMCMC
# (Intercept) 0.3355777 -0.6093231 1.283184    16634 0.488758
AEvoB0 <- rfnorm( length( AEvo.Bayes0$Sol[,1] ), mean( AEvo.Bayes0$Sol[,1] ), sd( AEvo.Bayes0$Sol[,1] ) )
mean( AEvoB0 )	;	hpd( AEvoB0 ) 		 ;		 Mode( AEvoB0 )
# 0.4775428		5.870392e-05 -to- 1.148672e+00		0.65104
AEvo.Bayes1 <- MCMCglmm(AEvo ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
AEvo.Bayes2 <- MCMCglmm(AEvo ~ 1 + trait.type * taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
AEvo.Bayes3 <- MCMCglmm(AEvo ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
AEvo.Bayes4 <- MCMCglmm(AEvo ~ 1 + trait.type * taxon2 + trait.no, nitt=500000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
# Bayesian approach indicates model3 is the best fitting
AEvo.Bayes1$DIC ; AEvo.Bayes2$DIC ; AEvo.Bayes3$DIC	;	AEvo.Bayes4$DIC
# 471.9372			473.4084			434.9815			437.3735
# the choice between model2 & model3 again makes little quantitative difference <- estimates correlated at >0.94
cor( c(colMeans( AEvo.Bayes2$Sol )[1:5]), c(colMeans( AEvo.Bayes3$Sol )) )
# going with model3, erring on the side of the more complex models with additional covariates.
summary( AEvo.Bayes3 )$solutions
# post.mean   l-95% CI  u-95% CI eff.samp     pMCMC
# (Intercept)  0.02891164 -2.8527564 2.9017820     3167 0.9838964
# trait.typeM  3.08145461 -2.5856689 8.9037925     3167 0.2854436
# trait.typeS  0.48952770 -2.6076508 3.4216634     3167 0.7641301
# taxon2P     -0.48971460 -3.0229550 1.9963982     3167 0.7199242
# trait.no     0.01663702 -0.6234972 0.6099593     3167 0.9718977
AEvo.estimates <- cbind( AEvo.Bayes3$Sol[,1],
( AEvo.Bayes3$Sol[,1] + AEvo.Bayes3$Sol[,2] ),
( AEvo.Bayes3$Sol[,1] + AEvo.Bayes3$Sol[,3] ),
( AEvo.Bayes3$Sol[,1] + AEvo.Bayes3$Sol[,4] ),
( AEvo.Bayes3$Sol[,1] +AEvo.Bayes3$Sol[,2] +AEvo.Bayes3$Sol[,4] ),
( AEvo.Bayes3$Sol[,1] +AEvo.Bayes3$Sol[,3] +AEvo.Bayes3$Sol[,4] ) )
AEvo.estimates <- FoldedNormal( AEvo.estimates )
colnames(AEvo.estimates) <- c('A.LH','A.M','A.S','P.LH','P.M','P.S')
# Tabulate estimates
apply( AEvo.estimates, 2, mean )
apply( AEvo.estimates, 2, Mode )
apply( AEvo.estimates, 2, hpd )
# A.LH       A.M       A.S      P.LH       P.M       P.S
# 1.171787 3.692067 1.948575 1.292362 3.402012 1.468000
# 0.5468495 1.7414221 1.2911786 0.7985577 0.6695847 1.6241952
# 0.0001642 0.0062499 0.0007516 0.002241 0.001609879 0.000541
# 2.9434666 8.5480446 4.7517676 3.198912 7.825105986 3.618291
```
Here are the results of our selected model for 'average evolvability'; filled points for estimates for animals, open points for plants, lines are the extent of the 95% credible intervals from the posterior distribution.
```{r AEvo_results, results='hide', fig.height=4, fig.width=4, echo=FALSE}
# AEvo plot
AEvofixed <- apply( AEvo.estimates, 2, mean )
plot(AEvofixed, type="n", xaxt="n", ylab="AEvo values", xlab="Trait type", xlim=c(0.7,3.3), ylim=c(0, 12), main="Average Evolvability")
axis(side=1, c("LH","M","S"), at=c(1,2,3))
lines( c(1,1), c(hpd(AEvo.estimates[,1])), lwd=2 )
lines( c(2,2), c(hpd(AEvo.estimates[,2])), lwd=2 )
lines( c(3,3), c(hpd(AEvo.estimates[,3])), lwd=2 )
lines( c(1.1,1.1), c(hpd(AEvo.estimates[,4])), lwd=2 )
lines( c(2.1,2.1), c(hpd(AEvo.estimates[,5])), lwd=2 )
lines( c(3.1,3.1), c(hpd(AEvo.estimates[,6])), lwd=2 )
points( 1:3, AEvofixed[1:3], pch=16, cex=2)
#animals - filled points ^ #plants - open points v
points( 1.1:3.1, AEvofixed[4:6], pch=21, bg="white", cex=2)
```
*Interlude 2*
At this point we compared the values for 'average evolvability' and *tgv*. The relationship between these two **G** structure metrics is strong, and apparent whether or not we log-transform the values.
```{r AEvo_vs_TGV_plot, results='hide', fig.height=4, fig.width=9, echo=FALSE}
# AEvo versus TGV
# REMINDER - the plot is only logged to make it easy to see
par( mfrow= c(1,2) )
mycor <- cor( log10( gmats$TGV), log10( gmats$AEvo) )	# 0.987
plot( log10( gmats$TGV), log10( gmats$AEvo), xlab="(log) total gen. var.", ylab="(log) average evo." )
abline( lm( log10( gmats$AEvo) ~ log10( gmats$TGV) ), col="red" )
text( -1, 1, paste( "cor=", round(mycor, 3), sep='', coll='' ) )
mycor2 <- cor( gmats$TGV, gmats$AEvo)	# 0.999
plot( gmats$TGV, gmats$AEvo, xlab="total gen. var.", ylab="average evo." )
abline( lm( gmats$AEvo ~ gmats$TGV ), col="red" )
text( 100, 55, paste( "cor=", round(mycor2, 3), sep='', coll='' ) )
mtext( text="TGV & AEvo are highly correlated", side=3, line=2, at=-200 )
par( mfrow=c(1,1))
```
The next code block performs the model selection for 'eigenvalue eveness'. For this metric the BIC, bootstrap and DIC (Bayesian) approaches were all in agreement in supporting model1, which was: `Even ~ trait.type + taxon2 + trait.no + random(study.code)`.
```{r model_selection_for_eveness, echo=FALSE, results='hide', message=FALSE}
Even.reml1 <- lmer(Even ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
Even.reml2 <- lmer(Even ~ 1 + trait.type * taxon2 + trait.no + (1|study.code), data=gmats)
Even.reml3 <- lmer(Even ~ 1 + trait.type + taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
Even.reml4 <- lmer(Even ~ 1 + trait.type * taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
# clear support from BIC for model1
BICtab( Even.reml1, Even.reml2, Even.reml3, Even.reml4, weights=T, nobs=nrow(gmats) )
# dBIC df weight
# Even.reml1  0.0 7  0.85936
# Even.reml3  4.4 8  0.09557
# Even.reml2  6.1 9  0.04057
# Even.reml4 10.5 10 0.00451
# model 1 vs model 3
LikRatioSim <- function( mod ) {
y.sim <- simulate(mod, nsim = 1)  # one set of simulated data
model.lower <- lmer(y.sim$sim_1 ~ 1 + trait.type + taxon2 + trait.no + (1|study.code), data=gmats)
model.full  <- lmer(y.sim$sim_1 ~ 1 + trait.type + taxon2 + trait.no + (1|study.code) + (1|species), data=gmats)
LRSim <-  -as.numeric(deviance(model.full) - deviance(model.lower))
return(LRSim)
rm(y.sim, model.lower, model.full, LRSim)
}
LikRatParBoot <- replicate(n = 1000, LikRatioSim( Even.reml1 ))
LR.model <- -as.numeric(deviance( Even.reml3 ) - deviance( Even.reml1 ))
mean(c((LikRatParBoot > LR.model), 1))
# 0.425 no support for stepping up to model 3
Even.Bayes1 <- MCMCglmm(Even ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
Even.Bayes2 <- MCMCglmm(Even ~ 1 + trait.type * taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ study.code, prior= myprior1 )
Even.Bayes3 <- MCMCglmm(Even ~ 1 + trait.type + taxon2 + trait.no, nitt=100000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
Even.Bayes4 <- MCMCglmm(Even ~ 1 + trait.type * taxon2 + trait.no, nitt=500000, burnin=5000, thin=30, data=gmats, verbose=F, random= ~ idh(trait.type):study.code + species, prior= myprior3 )
# model 1 is supported across the board
Even.Bayes1$DIC	; Even.Bayes2$DIC	; Even.Bayes3$DIC ;	Even.Bayes4$DIC
# -43.71037			-43.40248		-35.102		-32.53772
summary( Even.Bayes1 )$solutions
# post.mean   l-95% CI   u-95% CI eff.samp        pMCMC
# (Intercept)  0.517137942  0.3248217 0.72888772 2976.144 0.0003157562
# trait.typeM -0.032967906 -0.2072599 0.15582019 2672.422 0.7098200189
# trait.typeS  0.121768106 -0.0847587 0.34980164 3167.000 0.2797600253
# taxon2P     -0.012270879 -0.2096049 0.18496107 3167.000 0.9125355226
# trait.no    -0.005475639 -0.0374283 0.02381878 3003.118 0.7218187559
Even.estimates <- cbind( Even.Bayes1$Sol[,1],
( Even.Bayes1$Sol[,1] + Even.Bayes1$Sol[,2] ),
( Even.Bayes1$Sol[,1] + Even.Bayes1$Sol[,3] ),
( Even.Bayes1$Sol[,1] + Even.Bayes1$Sol[,4] ),
( Even.Bayes1$Sol[,1] +Even.Bayes1$Sol[,2] +Even.Bayes1$Sol[,4]),
( Even.Bayes1$Sol[,1] +Even.Bayes1$Sol[,3] +Even.Bayes1$Sol[,4] ) )
Even.estimates <- FoldedNormal( Even.estimates )
colnames(Even.estimates) <- c('A.LH','A.M','A.S','P.LH','P.M','P.S')
# Tabulate estimates
apply( Even.estimates, 2, mean )
apply( Even.estimates, 2, Mode )
apply( Even.estimates, 2, hpd )
# A.LH       A.M       A.S      P.LH       P.M       P.S
# 0.5117348 0.4863453 0.6360569 0.4987666 0.4731764 0.6242820
# 0.4289423 0.3762670 0.8149248 0.5339408 0.5757301 0.5496561
# 0.3203705 0.2968269 0.3823017 0.2498971 0.2466708 0.4255370
# 0.7088060 0.6679766 0.8793206 0.7469892 0.7048321 0.8508209
```
Here are the results of our selected model for 'eigenvalue eveness'; filled points for estimates for animals, open points for plants, lines are the extent of the 95% credible intervals from the posterior distribution as above. NB: "high values of E suggest that genetic variance is evenly distributed among the measured traits".
```{r eveness_results, results='hide', fig.height=4, fig.width=4, echo=FALSE}
Evenfixed <- apply( Even.estimates, 2, mean )
plot(Evenfixed, type="n", xaxt="n", ylab="Evenness values", xlab="Trait type", xlim=c(0.7,3.3), ylim=c(0,1), main="Evenness")
axis(side=1, c("LH","M","S"), at=c(1,2,3))
lines( c(1,1), c(hpd(Even.estimates[,1])), lwd=2 )
lines( c(2,2), c(hpd(Even.estimates[,2])), lwd=2 )
lines( c(3,3), c(hpd(Even.estimates[,3])), lwd=2 )
lines( c(1.1,1.1), c(hpd(Even.estimates[,4])), lwd=2 )
lines( c(2.1,2.1), c(hpd(Even.estimates[,5])), lwd=2 )
lines( c(3.1,3.1), c(hpd(Even.estimates[,6])), lwd=2 )
points( 1:3, Evenfixed[1:3], pch=16, cex=2)
#animals - filled points ^ #plants - open points v
points( 1.1:3.1, Evenfixed[4:6], pch=21, bg="white", cex=2)
